
# Frameworks
- LlamaIndex, LangChain, haystack, embedchain, semantic kernel, vector_flow

# Ragna
- high-level library for RAG pipelines
- with web API, web UI
- with vector stores
- simple API LLMs
- very new, not very comprehensive, not very well documented yet
- seems to rely on AutoGPTQ, which needs CUDA
    - An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm.


# Llama.cpp
- C++ implementation of LLMs, wrapper for LLMs
- LLM inference without any dependencies
- many supported open-source LLMs
- many bindings (eg Python)
- many UI libs
- https://github.com/ggerganov/llama.cpp
- https://github.com/abetlen/llama-cpp-python
- Models in GGUF format


# Ollama
- LLM wrapper
- offers many LLMs in GGUF format
- integrates with lots of frontends and packages



# Llama-index




# Resources 
## RAG
- https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6
- https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b
- https://www.marktechpost.com/2023/12/29/this-ai-paper-outlines-the-three-development-paradigms-of-rag-in-the-era-of-llms-naive-rag-advanced-rag-and-modular-rag/


## Ollama
- https://www.markhneedham.com/blog/2023/10/18/ollama-hugging-face-gguf-models/

## Llama.cpp
- https://www.linkedin.com/pulse/three-steps-run-llama-2-7b-chat-model-any-cpu-machine-nirmal-patel-3pw9f